{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Download Ngrok to tunnel the tensorboard port to an external port\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006 &\",\n                        \"./ngrok http 6006 &\"\n                        ]]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:54:20.802179Z","iopub.execute_input":"2021-12-09T19:54:20.802667Z","iopub.status.idle":"2021-12-09T19:54:23.004873Z","shell.execute_reply.started":"2021-12-09T19:54:20.802587Z","shell.execute_reply":"2021-12-09T19:54:23.002303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","metadata":{"execution":{"iopub.status.busy":"2021-12-09T19:54:36.013688Z","iopub.execute_input":"2021-12-09T19:54:36.01451Z","iopub.status.idle":"2021-12-09T19:54:36.7934Z","shell.execute_reply.started":"2021-12-09T19:54:36.014463Z","shell.execute_reply":"2021-12-09T19:54:36.792302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#!pip install gdown\n#!gdown --id 1lhyqkIn63bohxV7l4599zgD7R93TCkyM\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport sys\nfrom tqdm.notebook import tqdm\nfrom matplotlib import pyplot as plt\n%matplotlib inline \n\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import callbacks\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nimport shutil\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n\ntrain_size = 1000\ntotal_train_size = 5000\nfilas_test = 1000\ns = 300\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"3036037c-4baf-4ddd-9902-255090a33d2f","_cell_guid":"a1eb5634-59c3-4f99-93a7-97fcd94d173c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:54:42.511287Z","iopub.execute_input":"2021-12-09T19:54:42.511875Z","iopub.status.idle":"2021-12-09T19:54:55.578198Z","shell.execute_reply.started":"2021-12-09T19:54:42.511828Z","shell.execute_reply":"2021-12-09T19:54:55.577424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/medical-masks-part7/df_part_7.csv')\ndata_train = data_train.sample(frac=1)\ndata_train.head()","metadata":{"_uuid":"466eeca0-e68c-403d-9fe8-700c9907342e","_cell_guid":"82148c37-919d-445a-bba4-0d35bb2b0323","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:54:55.579998Z","iopub.execute_input":"2021-12-09T19:54:55.58027Z","iopub.status.idle":"2021-12-09T19:54:55.634896Z","shell.execute_reply.started":"2021-12-09T19:54:55.580218Z","shell.execute_reply":"2021-12-09T19:54:55.63409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train[:1000].groupby('TYPE').count()","metadata":{"_uuid":"1b7a0524-22b6-47c8-ad38-f76dc4ca85dd","_cell_guid":"c6e0f88f-84fb-4eb0-99eb-a261121ced55","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:54:55.636202Z","iopub.execute_input":"2021-12-09T19:54:55.636472Z","iopub.status.idle":"2021-12-09T19:54:55.658321Z","shell.execute_reply.started":"2021-12-09T19:54:55.636439Z","shell.execute_reply":"2021-12-09T19:54:55.65761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_imgs(start, stop):\n    X_train = []\n    y_train = data_train['TYPE'][start:stop]-1\n    dirname = '/kaggle/input/medical-masks-part7/images'\n    \n    filenames = data_train[start:stop].name\n    for filename in tqdm(filenames):\n        image = cv2.imread(dirname + \"/\" + filename, cv2.COLOR_BGR2RGB)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image_array = cv2.resize(image, (s,s))\n        X_train.append(list(image_array))\n    \n    \n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n\n    X_train = X_train / 255\n    y_train = to_categorical(y_train, num_classes=4)\n\n    X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, test_size=.35, shuffle=True)\n    \n    return [X_train, X_val, y_train, y_val]","metadata":{"_uuid":"4df4f2d0-b882-4d51-b3a5-b96d0223f3ee","_cell_guid":"95cf9489-cc6b-4b4b-82fc-a7b54cbf8aca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:54:55.660074Z","iopub.execute_input":"2021-12-09T19:54:55.66036Z","iopub.status.idle":"2021-12-09T19:54:55.66786Z","shell.execute_reply.started":"2021-12-09T19:54:55.660315Z","shell.execute_reply":"2021-12-09T19:54:55.666991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Definition","metadata":{"_uuid":"c6b94669-c5d1-4449-a519-1ec98d1a7239","_cell_guid":"733dca2a-3ab8-40e6-b8c7-83fcb2dc9027","trusted":true}},{"cell_type":"code","source":"# Define a simple sequential model\nfrom keras.applications.xception import Xception\nmodel=Xception(include_top = False, weights = 'imagenet', input_shape=(s,s,3))\nflattened = tf.keras.layers.Flatten()(model.output)\n\nfc1 = tf.keras.layers.Dense(4, activation='softmax', name=\"AddedDense2\")(flattened)\n\nmodel = tf.keras.models.Model(inputs=model.input, outputs=fc1) \n\n# Display the model's architecture\nmodel.summary()\n\ntf.keras.utils.plot_model(\n     model,\n     to_file=\"/kaggle/working/model.png\",\n     show_shapes=True,\n     show_layer_names=True,\n     rankdir=\"TB\",\n     expand_nested=True,\n     dpi=96,\n )","metadata":{"_uuid":"97ec0545-0dbf-4843-a687-549c8da65196","_cell_guid":"6bbb81f4-f79d-4f06-973f-c258d2420eda","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:54:55.671473Z","iopub.execute_input":"2021-12-09T19:54:55.671799Z","iopub.status.idle":"2021-12-09T19:55:02.454492Z","shell.execute_reply.started":"2021-12-09T19:54:55.671764Z","shell.execute_reply":"2021-12-09T19:55:02.453129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working","metadata":{"_uuid":"4c480f51-6662-4c65-aee8-3d547d7895de","_cell_guid":"4deacd9d-21b1-4f8a-841d-f47ef09cd744","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:55:02.457054Z","iopub.execute_input":"2021-12-09T19:55:02.457878Z","iopub.status.idle":"2021-12-09T19:55:02.464922Z","shell.execute_reply.started":"2021-12-09T19:55:02.457842Z","shell.execute_reply":"2021-12-09T19:55:02.464207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping   \ncallbacks_list = [  \n    ModelCheckpoint('/kaggle/working/AMD.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True),\n]  ","metadata":{"_uuid":"6bce26a5-0969-4877-bb3c-d0bbcc6ebf3e","_cell_guid":"e9c4bc7b-2f00-42e6-a9f0-112ca8a550c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:55:02.466513Z","iopub.execute_input":"2021-12-09T19:55:02.467271Z","iopub.status.idle":"2021-12-09T19:55:02.473212Z","shell.execute_reply.started":"2021-12-09T19:55:02.467224Z","shell.execute_reply":"2021-12-09T19:55:02.472434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\",\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nimport datetime\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","metadata":{"_uuid":"777c6f29-c0cb-45f3-b8c1-25d500054d0e","_cell_guid":"d2827674-33e1-46c1-b202-1d4b4b08ff3e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:55:02.474558Z","iopub.execute_input":"2021-12-09T19:55:02.47496Z","iopub.status.idle":"2021-12-09T19:55:02.837354Z","shell.execute_reply.started":"2021-12-09T19:55:02.474927Z","shell.execute_reply":"2021-12-09T19:55:02.836347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{"_uuid":"0ea098fd-7b70-4aea-8078-27293ec29447","_cell_guid":"557ff517-0dcc-4ff1-8026-8c1499998ae0","trusted":true}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = load_imgs(0, 1000)\n\nhistory = model.fit(X_train, y_train, epochs=30, verbose=1, validation_data=(X_val,y_val), callbacks=[tensorboard_callback])","metadata":{"_uuid":"04de463b-0575-4c77-a22c-8506c15060de","_cell_guid":"ec32e2fa-571a-4212-9135-0a838ebda93a","collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-09T19:55:02.839801Z","iopub.execute_input":"2021-12-09T19:55:02.840506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"_uuid":"33e6ecf7-51a0-45f4-8310-b9248318e50f","_cell_guid":"265e3642-4d4d-4500-be53-848a72611ca3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/trained_model.h5')","metadata":{"_uuid":"4732a7dc-b1f4-44d2-873c-35497aff2a54","_cell_guid":"953cd132-a574-4108-8378-e784a9567fa8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Prediction","metadata":{"_uuid":"dfea5596-2db4-48af-8181-d76899c8edad","_cell_guid":"8c86e332-2d08-4adc-b9dd-4e85e9a8becf","trusted":true}},{"cell_type":"code","source":"y_test = data_train['TYPE'][-filas_test:]-1\ny_test = np.array(y_test)","metadata":{"_uuid":"e964a98a-2933-45b4-a4ba-3da3bde8e22e","_cell_guid":"92fda751-4c4f-4614-a711-850580e7b469","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = []\ny_test = data_train['TYPE'][-filas_test:]-1\ndirname = '/kaggle/input/medical-masks-part7/images'\n    \nfilenames = data_train[-filas_test:].name\nfor filename in tqdm(filenames):\n    imframe = cv2.imread(dirname + \"/\" + filename)\n    imframe = cv2.cvtColor(imframe, cv2.COLOR_BGR2RGB)\n    imframe = cv2.resize(imframe, (s,s))\n    X_test.append(imframe)\n\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\nX_test = X_test / 255\n#y_test = to_categorical(y_test, num_classes=4)","metadata":{"_uuid":"35274601-f700-4cdc-b5ab-2248a7da1b84","_cell_guid":"0c2c0c29-2954-49a1-8730-5754e9958009","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = keras.models.load_model('trained_model_1.h5')\n\nresults = model.predict(X_test)\n\nresults = np.argmax(results,axis = 1)\n#y_test = np.argmax(y_test,axis = 1)","metadata":{"_uuid":"d71b42b7-37c6-495b-a308-2cdc4022402b","_cell_guid":"570e21fc-e15d-4a8b-b52f-dbe9632c543e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['results'] = list(results)\ndf['y_test'] = list(y_test)\ndf['name'] = list(np.array(data_train.name[-filas_test:]))\ndf.loc[df['y_test'] == df['results']].count() / df.shape[0]","metadata":{"_uuid":"35736bbb-897c-4a82-b443-cbe9a46c54df","_cell_guid":"e041b841-18ff-4d96-8c19-61c6babfd303","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fallos = df.loc[(df['y_test'] == 0) & (df['results'] == 3)]\n\nprint(fallos.shape)","metadata":{"_uuid":"d6646ae7-7728-4c1d-853b-f10e147c15d2","_cell_guid":"ccc65c7a-81d6-4bb7-a898-0a784bd35634","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"fallo = fallos.iloc[1,:]\n\nimframe = cv2.imread(dirname + \"/\" + fallo['name'])\nimframe = cv2.cvtColor(imframe, cv2.COLOR_BGR2RGB)\n#imframe = cv2.resize(imframe, (s,s))\n\nplt.imshow(imframe)\n\ntipos = [\n    'Mascarilla correctamente puesta',\n    'Mascarilla por debajo de la nariz',\n    'Mascarilla en la barbilla',\n    'Sin mascarilla'\n]\n\nprint('La foto es del tipo: {}, pero la red la clasifico como tipo: {}'.format(tipos[fallo.y_test], tipos[fallo.results]))","metadata":{"_uuid":"8c44602d-69ad-413d-82af-c10c8f0460a0","_cell_guid":"b43e76f0-5bf3-46de-9e3e-f8549c3ca39f","jupyter":{"outputs_hidden":false}}}]}